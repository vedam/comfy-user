{"id":"f14c6566-993e-4413-bd11-9c7f2ca07fd1","revision":0,"last_node_id":44,"last_link_id":62,"nodes":[{"id":8,"type":"VAEDecode","pos":[1160,150],"size":[160,50],"flags":{},"order":14,"mode":0,"inputs":[{"localized_name":"samples","name":"samples","type":"LATENT","link":22},{"localized_name":"vae","name":"vae","type":"VAE","link":25}],"outputs":[{"localized_name":"IMAGE","name":"IMAGE","type":"IMAGE","slot_index":0,"links":[47]}],"properties":{"cnr_id":"comfy-core","ver":"0.7.0","Node name for S&R":"VAEDecode"},"widgets_values":[]},{"id":20,"type":"Reroute","pos":[970,790],"size":[75,26],"flags":{},"order":13,"mode":0,"inputs":[{"name":"","type":"*","link":24}],"outputs":[{"name":"","type":"VAE","links":[25]}],"properties":{"showOutputText":false,"horizontal":false}},{"id":31,"type":"SaveImage //ZImagePowerNodes","pos":[1360,150],"size":[540,760],"flags":{},"order":15,"mode":0,"inputs":[{"localized_name":"images","name":"images","type":"IMAGE","link":47},{"localized_name":"filename_prefix","name":"filename_prefix","type":"STRING","widget":{"name":"filename_prefix"},"link":null},{"localized_name":"civitai_compatible_metadata","name":"civitai_compatible_metadata","type":"BOOLEAN","widget":{"name":"civitai_compatible_metadata"},"link":null}],"outputs":[],"properties":{"cnr_id":"z-image-power-nodes","ver":"ad23ca58af15ecf4e213aad7ce5e6d9462e63c7c","Node name for S&R":"SaveImage //ZImagePowerNodes"},"widgets_values":["ZImage/%date:yyyy_MM_dd%/ZI",true]},{"id":35,"type":"UnetLoaderGGUF","pos":[-980,-40],"size":[380,100],"flags":{},"order":0,"mode":0,"inputs":[{"localized_name":"unet_name","name":"unet_name","type":"COMBO","widget":{"name":"unet_name"},"link":null}],"outputs":[{"localized_name":"MODEL","name":"MODEL","type":"MODEL","links":[55]}],"properties":{"cnr_id":"comfyui-gguf","ver":"1.1.8","Node name for S&R":"UnetLoaderGGUF","aux_id":"city96/ComfyUI-GGUF"},"widgets_values":["z_image_turbo-Q5_K_S.gguf"],"color":"#322","bgcolor":"#533","shape":1},{"id":36,"type":"CLIPLoaderGGUF","pos":[-980,100],"size":[380,110],"flags":{},"order":1,"mode":0,"inputs":[{"localized_name":"clip_name","name":"clip_name","type":"COMBO","widget":{"name":"clip_name"},"link":null},{"localized_name":"type","name":"type","type":"COMBO","widget":{"name":"type"},"link":null}],"outputs":[{"localized_name":"CLIP","name":"CLIP","type":"CLIP","links":[54]}],"properties":{"cnr_id":"comfyui-gguf","ver":"1.1.8","Node name for S&R":"CLIPLoaderGGUF","aux_id":"city96/ComfyUI-GGUF"},"widgets_values":["Qwen3-4B.i1-Q5_K_S.gguf","lumina2"],"color":"#322","bgcolor":"#533","shape":1},{"id":37,"type":"VAELoader","pos":[-980,250],"size":[380,90],"flags":{},"order":2,"mode":0,"inputs":[{"localized_name":"vae_name","name":"vae_name","type":"COMBO","widget":{"name":"vae_name"},"link":null}],"outputs":[{"localized_name":"VAE","name":"VAE","type":"VAE","links":[56]}],"properties":{"cnr_id":"comfy-core","ver":"0.3.75","Node name for S&R":"VAELoader"},"widgets_values":["ae.safetensors"],"color":"#322","bgcolor":"#533","shape":1},{"id":39,"type":"Reroute","pos":[70,150],"size":[75,26],"flags":{},"order":7,"mode":0,"inputs":[{"name":"","type":"*","link":55}],"outputs":[{"name":"","type":"MODEL","links":[57]}],"properties":{"showOutputText":false,"horizontal":false}},{"id":19,"type":"Reroute","pos":[200,790],"size":[75,26],"flags":{},"order":11,"mode":0,"inputs":[{"name":"","type":"*","link":59}],"outputs":[{"name":"","type":"VAE","links":[24]}],"properties":{"showOutputText":false,"horizontal":false}},{"id":38,"type":"Reroute","pos":[70,210],"size":[75,26],"flags":{},"order":8,"mode":0,"inputs":[{"name":"","type":"*","link":54}],"outputs":[{"name":"","type":"CLIP","links":[60]}],"properties":{"showOutputText":false,"horizontal":false}},{"id":40,"type":"Reroute","pos":[70,250],"size":[75,26],"flags":{},"order":9,"mode":0,"inputs":[{"name":"","type":"*","link":56}],"outputs":[{"name":"","type":"VAE","links":[59]}],"properties":{"showOutputText":false,"horizontal":false}},{"id":41,"type":"Note","pos":[-1870,-80],"size":[870,550],"flags":{},"order":3,"mode":0,"inputs":[],"outputs":[],"title":"README","properties":{},"widgets_values":["Z-Image Power Nodes\n\n## Workflow Prerequisites ##\n\nThis workflow requires the following custom nodes, which can be obtained via ComfyUI-Manager:\n\n  * Z-Image Power Nodes: https://github.com/martin-rizzo/ComfyUI-ZImagePowerNodes\n  * ComfyUI-GGUF       : https://github.com/city96/ComfyUI-GGUF\n\n Additionally, ensure you have the following 3 models downloaded and placed in their respective\n directories within your ComfyUI installation:\n\n  z_image_turbo-Q5_K_S.gguf\n    * Download: https://huggingface.co/jayn7/Z-Image-Turbo-GGUF/blob/main/z_image_turbo-Q5_K_S.gguf\n    * Local Directory: `ComfyUI/models/diffusion_models/`\n\n  Qwen3-4B.i1-Q5_K_S.gguf\n    * Download: https://huggingface.co/mradermacher/Qwen3-4B-i1-GGUF/blob/main/Qwen3-4B.i1-Q5_K_S.gguf\n    * Local Directory: `ComfyUI/models/text_encoders/`\n\n  ae.safetensors\n    * Download: https://huggingface.co/Comfy-Org/z_image_turbo/blob/main/split_files/vae/ae.safetensors\n    * Local Directory: `Comfyui/models/vae/`\n\n## More Info ##\n\n- https://github.com/martin-rizzo/ComfyUI-ZImagePowerNodes\n- https://civitai.com/models/2322533/z-image-power-nodes\n\nCreated by Martin Rizzo\n  GitHub : https://github.com/martin-rizzo\n  CivitAI: https://civitai.com/user/Photographer\n  Reddit : https://www.reddit.com/user/FotografoVirtual\n"],"color":"#223","bgcolor":"#335","shape":1},{"id":18,"type":"ZSamplerTurbo //ZImagePowerNodes","pos":[870,150],"size":[250,480],"flags":{},"order":12,"mode":0,"inputs":[{"localized_name":"model","name":"model","type":"MODEL","link":57},{"localized_name":"positive","name":"positive","type":"CONDITIONING","link":61},{"localized_name":"latent_input","name":"latent_input","type":"LATENT","link":48},{"localized_name":"seed","name":"seed","type":"INT","widget":{"name":"seed"},"link":null},{"localized_name":"steps","name":"steps","type":"INT","widget":{"name":"steps"},"link":null},{"localized_name":"denoise","name":"denoise","type":"FLOAT","widget":{"name":"denoise"},"link":null}],"outputs":[{"localized_name":"latent_output","name":"latent_output","type":"LATENT","links":[22]}],"properties":{"cnr_id":"z-image-power-nodes","ver":"7cb3b03f95eeae260ebbc2facdf6ba6c1e16e639","Node name for S&R":"ZSamplerTurbo //ZImagePowerNodes","aux_id":"martin-rizzo/ComfyUI-ZImagePowerNodes"},"widgets_values":[1,"fixed",9,1]},{"id":44,"type":"Note","pos":[-50,-160],"size":[420,250],"flags":{},"order":4,"mode":0,"inputs":[],"outputs":[],"properties":{},"widgets_values":["This workflow demonstrates how to define a custom style by connecting through the \"customization\" input in the \"Style & Prompt Encoder\" node.\n\nA multi-line string must be defined using the following format:\nEach line starting with \">>>\" (three greater-than signs) defines the name of the style. From there, all subsequent lines until the next \">>>\" define the content of that style. Within this content, the tag \"{$@}\" will be replaced by the prompt.\n\nWhile the example shows all styles being defined as \"Custom <N>\", this method can be used to redefine any of the available styles in the style selector."],"color":"#223","bgcolor":"#335","shape":1},{"id":32,"type":"EmptyZImageLatentImage //ZImagePowerNodes","pos":[530,20],"size":[316.9362396240234,130],"flags":{},"order":6,"mode":0,"inputs":[{"localized_name":"landscape","name":"landscape","type":"BOOLEAN","widget":{"name":"landscape"},"link":null},{"localized_name":"ratio","name":"ratio","type":"COMBO","widget":{"name":"ratio"},"link":null},{"localized_name":"size","name":"size","type":"COMBO","widget":{"name":"size"},"link":null},{"localized_name":"batch_size","name":"batch_size","type":"INT","widget":{"name":"batch_size"},"link":null}],"outputs":[{"localized_name":"LATENT","name":"LATENT","type":"LATENT","links":[48]}],"properties":{"cnr_id":"z-image-power-nodes","ver":"ad23ca58af15ecf4e213aad7ce5e6d9462e63c7c","Node name for S&R":"EmptyZImageLatentImage //ZImagePowerNodes"},"widgets_values":[false,"3:2  (photo)","medium (recommended)",1]},{"id":42,"type":"StylePromptEncoder //ZImagePowerNodes","pos":[200,210],"size":[660,570],"flags":{},"order":10,"mode":0,"inputs":[{"localized_name":"clip","name":"clip","type":"CLIP","link":60},{"localized_name":"customization","name":"customization","shape":7,"type":"STRING","link":62},{"localized_name":"category","name":"category","type":"COMBO","widget":{"name":"category"},"link":null},{"localized_name":"style","name":"style","type":"COMBO","widget":{"name":"style"},"link":null},{"localized_name":"text","name":"text","type":"STRING","widget":{"name":"text"},"link":null}],"outputs":[{"localized_name":"CONDITIONING","name":"CONDITIONING","type":"CONDITIONING","links":[61]},{"localized_name":"STRING","name":"STRING","type":"STRING","links":null}],"properties":{"cnr_id":"z-image-power-nodes","ver":"ad23ca58af15ecf4e213aad7ce5e6d9462e63c7c","Node name for S&R":"StylePromptEncoder //ZImagePowerNodes"},"widgets_values":["custom","\"Custom 3\"","A woman with short, spiky blonde hair is depicted from the chest up, aiming a large, dark gray firearm. Her hair is tousled and appears to be catching the light. She has blue eyes and shadow on her cheeks. She is wearing a white tank top with one strap visibly off her right shoulder. The firearm she holds is dark gray and appears to be a heavy weapon. A dark ancient castle is visible in the background on the right side. Her attire includes dark, torn shorts and ripped, dark stockings or tights on her legs."],"color":"#232","bgcolor":"#353","shape":1},{"id":43,"type":"PrimitiveStringMultiline","pos":[-450,320],"size":[576,960],"flags":{},"order":5,"mode":0,"inputs":[{"localized_name":"value","name":"value","type":"STRING","widget":{"name":"value"},"link":null}],"outputs":[{"localized_name":"STRING","name":"STRING","type":"STRING","links":[62]}],"title":"custom","properties":{"cnr_id":"comfy-core","ver":"0.12.3","Node name for S&R":"PrimitiveStringMultiline"},"widgets_values":[">>>CUSTOM 1\nYOUR CONTEXT:\nYou are an illustrator of dark and disturbing themes.\nYour illustration includes {$spicy-content-with} stippling textures, dramatic raking side lighting, and a dread-filled atmosphere that is oppressive and claustrophobic. High contrast emphasizes form and shadow, employing cinematic chiaroscuro for depth.\nYOUR DRAWING:\n{$@}\n\n\n>>>Custom 2\nYOUR CONTEXT:\nYou are a sci-fi pulp magazine illustrator from the 1940s.\nYour drawing is a lush, painted-style comic cover including {$spicy-content-with} dramatic, heroic lighting and a vivid \"Technicolor\" palette of saturated oranges, deep teals, and bright yellows. It features soft airbrushed textures, muscular anatomy, and a grainy film-stock finish that evokes a sense of retro-futuristic adventure.\nYOUR DRAWING:\n{$@}\n\n\n>>>custom 3\nYOUR CONTEXT:\nAn eye-level, realistic photo of a glass-encased advertising poster (mupi) located on a clean city sidewalk. There are subtle reflections of nearby buildings and trees on the glass surface. The lighting is natural overcast daylight.\nWHAT'S BEHIND THE REFLECTIVE GLASS:\nA faded and sun-faded, low quality printed advertisement, showing:\n{$@}\n\n\n>>>custom 4\nYOUR CONTEXT:\nAn eye-level, realistic photo of a glass-encased advertising poster (mupi) located on a clean city sidewalk. There are subtle reflections of nearby buildings and trees on the glass surface. The lighting is natural overcast daylight.\nWHAT'S BEHIND THE REFLECTIVE GLASS:\nA faded and sun-faded, low quality printed advertisement, showing:\n{$@}"]}],"links":[[22,18,0,8,0,"LATENT"],[24,19,0,20,0,"VAE"],[25,20,0,8,1,"VAE"],[47,8,0,31,0,"IMAGE"],[48,32,0,18,2,"LATENT"],[54,36,0,38,0,"CLIP"],[55,35,0,39,0,"MODEL"],[56,37,0,40,0,"VAE"],[57,39,0,18,0,"MODEL"],[59,40,0,19,0,"VAE"],[60,38,0,42,0,"CLIP"],[61,42,0,18,1,"CONDITIONING"],[62,43,0,42,1,"STRING"]],"groups":[{"id":2,"title":"GGUF MODELS","bounding":[-992,-112,400,580],"color":"#A88","font_size":24,"flags":{}}],"config":{},"extra":{"ds":{"scale":0.7513148009015777,"offset":[1873.4177448997068,550.3239861673064]},"frontendVersion":"1.35.9","workflowRendererVersion":"LG"},"version":0.4}